{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dde4c0b-65a4-4b05-9d58-d42b5d2c41a3",
   "metadata": {},
   "source": [
    "# Handling Graphs\n",
    "\n",
    "In PyG a single graph is described by an instance of `torch_geometric.data.Data`.\n",
    "By defaults, it can handles the following attributes:\n",
    "\n",
    "- `data.x`: Node feature matrix with shape `[num_nodes, num_node_features]`\n",
    "- `data.edge_index`: Graph connectivity in [COO](https://pytorch.org/docs/stable/sparse.html#sparse-coo-docs)(sparse representation) format with shape `[2, num_edges]` and type `torch.long`\n",
    "- `data.edge_attr`: Edge feature matrix with shape `[num_edges, num_edge_features]`\n",
    "- `data.y`: Target to train against (may have arbitrary shape), e.g., node-level targets of shape `[num_nodes, *]` or graph-level targets of shape `[1, *]`\n",
    "- `data.pos`: Node position matrix with shape `[num_nodes, num_dimensions]`\n",
    "\n",
    "None of these attributes are required and we can also add new attributes.\n",
    "\n",
    "A basic example of how to create a graph is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e6d4427-0f2c-4920-a9bb-ac8a65950d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/libpyg.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_St8optionalIN3c1017basic_string_viewIcEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_spline_conv/_basis_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n",
      "Node Features: tensor([[-1.,  0.,  1.]])\n",
      "Edges:\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index: torch.Tensor = torch.tensor([[0, 1, 1, 2],\n",
    "                                         [1, 0, 2, 1]], dtype=torch.long)\n",
    "x: torch.Tensor = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "data: Data = Data(x=x, edge_index=edge_index)\n",
    "print(data)\n",
    "print(f\"Node Features: {data.x.T}\")\n",
    "print(f\"Edges:\\n{data.edge_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9950e4-eb41-483a-acf3-b65daae238a5",
   "metadata": {},
   "source": [
    "This will create a graph with $3$ nodes with $1$ feature each and $4$ edges.\n",
    "Note that `edge_index` is created with $2$ separate `list`, the first is for `source` and the second is for `destination`.\n",
    "If we want to create `edge_index` from a list of index tuple we will do the following using `contiguos()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d758c638-3d36-4ac0-a32c-e81a6cec837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[3, 1], edge_index=[2, 4])\n",
      "Node Features: tensor([[-1.,  0.,  1.]])\n",
      "Edges:\n",
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 2, 1]])\n"
     ]
    }
   ],
   "source": [
    "edge_index: torch.Tensor = torch.tensor([[0, 1],\n",
    "                                         [1, 0],\n",
    "                                         [1, 2],\n",
    "                                         [2, 1]], dtype=torch.long)\n",
    "x: torch.Tensor = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index.t().contiguous())\n",
    "print(data)\n",
    "print(f\"Node Features: {data.x.T}\")\n",
    "print(f\"Edges:\\n{data.edge_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2b923-3c76-404c-bbca-455d80689664",
   "metadata": {},
   "source": [
    "The result is the same.\n",
    "\n",
    "It is necessary that the elements in `edge_index` only hold indices in the range `{ 0, ..., num_nodes - 1}`.\n",
    "This can be checked using `validate()` on the `Data` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7298ee18-85c6-4b2f-aea6-60335402bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is valid: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Graph is valid: {data.validate(raise_on_error=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda3c22-fc38-4a87-96f0-4a1c6368f78e",
   "metadata": {},
   "source": [
    "Since a `Data` object is composed by Tensors, we can tranfer the graph on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa843a9-9814-479f-830e-e098102d3ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features on: cuda:0\n",
      "Edges on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "data.to(device)\n",
    "print(f\"Features on: {data.x.device}\")\n",
    "print(f\"Edges on: {data.edge_index.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5e2d84-1e56-4a5c-ba7c-2ca8e7bde20a",
   "metadata": {},
   "source": [
    "# Importing a dataset\n",
    "\n",
    "PyG offers a wide range of ready to use datasets in the `torch_geometric.datasets` package. A full list of datasets can be found [here](https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html).\n",
    "For this example we will use `MNISTSuperpixels`, a graph variant of the common `MNIST` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd23071-c4f8-48d3-90ca-9a7b467f6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "\n",
    "MNIST_PATH = \"../datasets/MNISTSuperpixel\"\n",
    "dataset = MNISTSuperpixels(root=MNIST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4794823-5f8b-44f8-a87a-f8e354b15e3b",
   "metadata": {},
   "source": [
    "We can get some basic information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a10b47-aec2-4a57-8cf9-932307c4fde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTSuperpixels(60000)\n",
      "Classes: 10\n",
      "Node features: 1\n",
      "Edge features: 0\n"
     ]
    }
   ],
   "source": [
    "print(dataset)\n",
    "print(f\"Classes: {dataset.num_classes}\")\n",
    "print(f\"Node features: {dataset.num_node_features}\")\n",
    "print(f\"Edge features: {dataset.num_edge_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cdedb2-bb0b-40dd-9801-c61dd3d3f460",
   "metadata": {},
   "source": [
    "We have access to all the dataset and we can get a graph by direct access or slicing a subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f067de-d06b-4872-b4ca-a1623e4a1e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[75, 1], edge_index=[2, 1399], y=[1], pos=[75, 2])\n",
      "MNISTSuperpixels(100)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "sliced = dataset[:100]\n",
    "print(sliced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73014ff4-28db-46be-993b-59d34fd7d981",
   "metadata": {},
   "source": [
    "Like in PyTorch, PyG offers a `DataLoader` class in `torch_geometric.loader` module.\n",
    "A `Dataloader` is used to get batches from a dataset. \n",
    "Internally, DataLoader is just a regular PyTorch `torch.utils.data.DataLoader` that overwrites its `collate()` functionality, i.e., the definition of how a list of examples should be grouped together.\n",
    "\n",
    "In our example we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8331de89-5a24-4954-bcfb-ec4841105cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[225, 1], edge_index=[2, 4043], y=[3], pos=[225, 2], batch=[225], ptr=[4])\n",
      "Graphs in the batch: 3\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Batch\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=3)\n",
    "batch: Batch = next(iter(loader)) \n",
    "\n",
    "print(batch)\n",
    "print(f\"Graphs in the batch: {batch.num_graphs}\")\n",
    "print(batch.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a217c8-45e5-430b-ae38-f3c1403de2fc",
   "metadata": {},
   "source": [
    "The `DataLoader` returns an `iterator`. Each element is a subtype `Batch` of `Data` that contains an additional attribute called `batch`, which maps each node to its respective graph in the batch.\n",
    "In our example we have a `batch_size` of $3$, so each batch contains $3$ graphs. The property `batch` in fact contains integers from $0$ to $batch\\_size - 1$ indicating at which graph the node belogns.\n",
    "\n",
    "This is due the fact that PyG achieves parallelization over a `mini-batch` by creating sparse block diagonal adjacency matrices (defined by `edge_index`) and concatenating feature and target matrices in the node dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4776550c-dd71-438c-b9ea-292e71698473",
   "metadata": {},
   "source": [
    "# Mini-Batching\n",
    "Since graphs are one of the most general data structures that can hold any number of nodes or edges, for grouping them in to batches we can stack the adjacency matrices in a diagonal fashion (creating a giant graph that holds multiple isolated subgraphs), and node and target features are simply concatenated in the node dimension.\n",
    "$$\n",
    "\\begin{split}\\mathbf{A} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}.\\end{split}\n",
    "$$\n",
    "\n",
    "We have the following benefits:\n",
    "\n",
    "1. GNN operators that rely on a message passing scheme do not need to be modified since messages still cannot be exchanged between two nodes that belong to different graphs.\n",
    "\n",
    "2. There is no computational or memory overhead. For example, this batching procedure works completely without any padding of node or edge features. Note that there is no additional memory overhead for adjacency matrices since they are saved in a sparse fashion holding only non-zero entries, i.e., the edges.\n",
    "\n",
    "We can plot the gigant dense adjency matrix to understand the concatenation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12c6e3f5-b397-44a8-9ba9-7e40e5222638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix dimension: torch.Size([225, 225])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "adj = to_dense_adj(batch.edge_index)[0]\n",
    "print(f\"Matrix dimension: {adj.shape}\")\n",
    "plt.matshow(adj)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284f2bec-7075-4768-b089-33b8f852626b",
   "metadata": {},
   "source": [
    "# Create random graphs, join them and create a mini-batch\n",
    "\n",
    "## Create a random graph\n",
    "To create a basic random graph i.e a `Data` object which only contains $1$ node feature and a sparse graph representation, we can generate random tensors and construct `Data` like in the first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e98d69-6749-4879-b87a-804588558694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph is valid: True\n"
     ]
    }
   ],
   "source": [
    "def generate_random_graph(num_nodes: int = 75, num_edges: int = 1500) -> Data:\n",
    "    edges: torch.Tensor = torch.randint(0, num_nodes, (num_edges, 2), dtype=torch.long)\n",
    "    x: torch.Tensor = torch.rand((num_nodes, 1))\n",
    "    return Data(x=x, edge_index=edges.t().contiguous()).coalesce()\n",
    "\n",
    "\n",
    "data: Data = generate_random_graph()\n",
    "print(f\"Graph is valid: {data.validate(raise_on_error=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8adc01e-d38f-47b8-a39c-3fb4fabbea50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497 ms ± 7.07 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [generate_random_graph() for i in range(1000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f5740-a36b-4b64-930f-df0d93649931",
   "metadata": {},
   "source": [
    "## Create a Batch from generated data\n",
    "\n",
    "For creating a Batch from generated `Data` we can use the `classmethod` `Batch.from_data_list()`, from the module `torch_geometric.data.Batch` documented [here](https://pytorch-geometric.readthedocs.io/en/latest/generated/torch_geometric.data.Batch.html#torch_geometric.data.Batch.from_data_list).\n",
    "\n",
    "We have to provide a `List[Data]` and set the parameter `follow_batch` with a list of keys that we want to mantain the batch information. (In this example suppose we want to track batch information of `x`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99456015-f4aa-444d-87d3-a7a5a0dd456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[8, 1], x_batch=[8], x_ptr=[3], edge_index=[2, 14], batch=[8], ptr=[3])\n",
      "First data edges:\n",
      "tensor([[0, 1, 1, 2, 2, 2, 3],\n",
      "        [3, 0, 3, 0, 1, 3, 3]])\n",
      "Second data edges:\n",
      "tensor([[0, 1, 2, 2, 2, 3, 3],\n",
      "        [2, 0, 0, 1, 3, 2, 3]])\n",
      "Batch information for x: tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
      "ptr information: tensor([0, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "torch.manual_seed(2)\n",
    "\n",
    "generated_batch: Batch = Batch.from_data_list(\n",
    "    data_list=[generate_random_graph(4,10) for i in range(2)],\n",
    "    follow_batch=['x']\n",
    ")\n",
    "print(generated_batch)\n",
    "print(f\"First data edges:\\n{generated_batch[0].edge_index}\")\n",
    "print(f\"Second data edges:\\n{generated_batch[1].edge_index}\")\n",
    "print(f\"Batch information for x: {generated_batch.x_batch}\")\n",
    "print(f\"ptr information: {generated_batch.ptr}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a466aa8b-3d01-40ce-9742-07c6c2bef1b2",
   "metadata": {},
   "source": [
    "As we can see, if we access the `edge_index` attribute of a specific data, we get it's specific attribute.\n",
    "In `x_batch` we can find the index of the graph that has that attribute, i.e. the first four `x` are of graph at index $0$ and the others are of graph at index $1$.\n",
    "\n",
    "A global position information is stored in the field `ptr`. In this example it says that the first graph node features (`x`) are stored from `[0,4)` and the second is from `[4,8)`.\n",
    "\n",
    "Like in the previous section, we can plot the gigant matrix if we convert it to dense first.\n",
    "(For demonstration we will generate a new batch composed of 3 bigger random graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ded5ba32-ebbb-4f25-b92a-b870c0e61751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_batch: Batch = Batch.from_data_list(\n",
    "    data_list=[generate_random_graph(75,1500) for i in range(3)],\n",
    ")\n",
    "\n",
    "adj = to_dense_adj(plot_batch.edge_index)[0]\n",
    "plt.matshow(adj)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065687c6-0b77-40f1-9e97-130ef4178d20",
   "metadata": {},
   "source": [
    "# Concatenate Batches\n",
    "\n",
    "Concatenating batches is an expensive operation, since we have to convert the batches in `list`, concatenate them and then tranform them back in a `Batch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9734a600-e6f3-4c6a-8a9c-12044bb21855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[9, 1], edge_index=[2, 20], batch=[9], ptr=[4])\n",
      "Concatenated edge_index:\n",
      "tensor([[0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 5, 5, 6, 6, 7, 7, 8, 8],\n",
      "        [0, 2, 0, 1, 2, 0, 1, 2, 3, 4, 5, 5, 4, 5, 7, 8, 6, 8, 7, 8]])\n",
      "Concateted ptr:\n",
      "tensor([0, 3, 6, 9])\n",
      "torch.Size([9, 9])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "first_batch: Batch = Batch.from_data_list([generate_random_graph(3, 10) for i in range(1)])\n",
    "second_batch: Batch = Batch.from_data_list([generate_random_graph(3, 10) for i in range(2)])\n",
    "\n",
    "concatenated: Batch = Batch.from_data_list(\n",
    "    first_batch.to_data_list() +\n",
    "    second_batch.to_data_list()\n",
    ")\n",
    "\n",
    "print(concatenated)\n",
    "print(f\"Concatenated edge_index:\\n{concatenated.edge_index}\")\n",
    "print(f\"Concateted ptr:\\n{concatenated.ptr}\")\n",
    "\n",
    "adj = to_dense_adj(concatenated.edge_index)[0]\n",
    "plt.matshow(adj)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dfb3b9-d055-4777-8329-f60bbeeec94b",
   "metadata": {},
   "source": [
    "# Dense representation\n",
    "\n",
    "Sometimes want to use the dense representation.\n",
    "Suppose a more complex example where `num_nodes` vary across graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c2e365-9f04-4004-b863-022f99f685f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features: tensor([[0.7487, 0.7893, 0.5693, 0.7754, 0.1346, 0.1483, 0.3696, 0.6327, 0.3391,\n",
      "         0.0582, 0.3220, 0.1224]]), torch.Size([12, 1])\n",
      "Batch vector: tensor([0, 0, 0, 0, 1, 1, 1, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_batch\n",
    "\n",
    "data: Batch = Batch.from_data_list([\n",
    "    generate_random_graph(4, 10),\n",
    "    generate_random_graph(3, 10),\n",
    "    generate_random_graph(5, 10)\n",
    "])\n",
    "print(f\"Node features: {data.x.T}, {data.x.shape}\")\n",
    "print(f\"Batch vector: {data.batch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5138a655-444f-45be-98b0-5e0da24d6bdb",
   "metadata": {},
   "source": [
    "We can see that the node feature is a `12x1` tensor, because we have $12$ total nodes and $1$ feature.\n",
    "The bacth vector indicates as usual, at which graphs the nodes belogs.\n",
    "\n",
    "To get a dense node feature tensor, we can use [to_dense_batch](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.to_dense_batch).\n",
    "\n",
    "We have to pass the node feature `x`, i.e. `data.x` and the batch vector, i.e. `data.batch`.\n",
    "The results will be $2$ tensors: the `output` and a `mask`.\n",
    "The output shape will be `[batch_size, max_num_nodes, features]`. In our example we have, $3$ graphs, the biggest graph has $5$ nodes and theri is just $1$ feature, so we will have a shape of `[3, 5, 1]`.\n",
    "\n",
    "Note that the smaller graphs will be filled with default values (like `0.`).\n",
    "To regognize real nodes and fake nodes we will use the `mask`.\n",
    "The `mask` is a boolean tesor of shape `[batch_size, max_num_node]`. A `True` entry indicates the presence of a real node, and `False` indicates that the node is fake and has been added to match dimension.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d5ef05b-16ca-4800-ac64-4feae9e4b4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 5, 1])\n",
      "torch.Size([3, 5])\n",
      "tensor([[ True,  True,  True,  True, False],\n",
      "        [ True,  True,  True, False, False],\n",
      "        [ True,  True,  True,  True,  True]])\n"
     ]
    }
   ],
   "source": [
    "out, mask = to_dense_batch(data.x, data.batch)\n",
    "print(out.shape)\n",
    "print(mask.shape)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2579c736-c008-49aa-995e-37d04c1df5cd",
   "metadata": {},
   "source": [
    "For representing a dense adjency matrix we use [to_dense_adj](https://pytorch-geometric.readthedocs.io/en/latest/modules/utils.html#torch_geometric.utils.to_dense_adj).\n",
    "\n",
    "We "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e9746a3-6a2c-4b13-b1cd-0b5f09a9cd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj = to_dense_adj(data.edge_index, data.batch)\n",
    "adj\n",
    "adj.shape  # batch_size, num_nodes, num_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad0ab655-f161-4c14-bb1d-471005871b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[5, 1], edge_index=[2, 8], batch=[5], ptr=[2])\n",
      "tensor([0.8081, 0.3924, 0.2132, 0.5028, 0.9025, 0.2942, 0.0811, 0.8372])\n",
      "tensor([[[0.8081, 0.0000, 0.3924, 0.0000, 0.0000],\n",
      "         [0.0000, 0.2132, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.5028, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.9025, 0.0000, 0.2942],\n",
      "         [0.0000, 0.0811, 0.0000, 0.0000, 0.8372]]])\n"
     ]
    }
   ],
   "source": [
    "edge_attr = torch.tensor([[1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                          [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "                          [1.0, 2.0, 3.0, 4.0, 5.0]])\n",
    "\n",
    "\n",
    "data_list = [generate_random_graph(5,10)]\n",
    "data = Batch.from_data_list(data_list)\n",
    "\n",
    "edge_attr = torch.rand((data.edge_index.shape[1]))\n",
    "print(data)\n",
    "print(edge_attr)\n",
    "\n",
    "data.edge_attr = edge_attr\n",
    "\n",
    "adj = to_dense_adj(data.edge_index, edge_attr=data.edge_attr)\n",
    "\n",
    "print(adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d22553-9da7-4c84-a70a-9fe9d0ad314e",
   "metadata": {},
   "source": [
    "# Convert back to sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a82a4261-750c-4576-baf4-69840cfebd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 0.],\n",
      "        [1., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1., 1.]])\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n",
      "[Data(x=[5, 1], edge_index=[2, 7]), Data(x=[4, 1], edge_index=[2, 9]), Data(x=[3, 1], edge_index=[2, 7])]\n",
      "[Data(x=[5, 1], edge_index=[2]), Data(x=[4, 1], edge_index=[2]), Data(x=[3, 1], edge_index=[2])]\n"
     ]
    }
   ],
   "source": [
    "from typing import Tuple, List\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "\n",
    "\n",
    "def densify(data: Batch) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    x, mask = to_dense_batch(data.x, data.batch)\n",
    "    adj = to_dense_adj(data.edge_index, data.batch)\n",
    "    return x, adj, mask\n",
    "\n",
    "\n",
    "def to_sparse_list(x, adj, mask, ptr) -> List[Data]:\n",
    "    data = []\n",
    "    for i in range(1, len(ptr)):\n",
    "        sparse_x = x[mask][ptr[i-1]:ptr[i]]\n",
    "        edge_index = dense_to_sparse(adj[i-1], mask)\n",
    "        data.append(Data(x=sparse_x, edge_index=edge_index))\n",
    "    return data\n",
    "\n",
    "\n",
    "test = Batch.from_data_list([\n",
    "    generate_random_graph(5, 10),\n",
    "    generate_random_graph(4, 10),\n",
    "    generate_random_graph(3, 10)\n",
    "])\n",
    "\n",
    "x, adj, mask = densify(test)\n",
    "\n",
    "print(adj[0])\n",
    "print(torch.transpose(adj, 1, 2)[0])\n",
    "\n",
    "print(Batch.to_data_list(test))\n",
    "print(to_sparse_list(x, adj, mask, test.ptr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
