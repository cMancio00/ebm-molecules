{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2b49e53-128c-4576-944d-75d105b6bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/libpyg.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_scatter/_scatter_cuda.so: undefined symbol: _ZN2at4_ops16div__Tensor_mode4callERNS_6TensorERKS2_St8optionalIN3c1017basic_string_viewIcEEE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:113: UserWarning: An issue occurred while importing 'torch-spline-conv'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_spline_conv/_basis_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(\n",
      "/home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/mancio/git/ebm-molecules/.venv/lib/python3.12/site-packages/torch_sparse/_spmm_cuda.so: undefined symbol: _ZN5torch8autograd12VariableInfoC1ERKN2at6TensorE\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.data import Dataset as pygDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Dataset as pygDataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "import torch as th\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Tuple, List, Sequence\n",
    "from dataclasses import dataclass\n",
    "from torch_geometric.datasets import MNISTSuperpixels\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "MNIST_PATH = \"../datasets/MNISTSuperpixel/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6227c0-0430-4fdd-839e-0e5e2e394962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MNISTSuperpixels(10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = MNISTSuperpixels(MNIST_PATH).to(device)[:10]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0bcb49-82b3-4f0b-9897-0d4d32142bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DenseData:\n",
    "    x: th.tensor\n",
    "    adj: th.tensor\n",
    "    mask: th.tensor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return (\n",
    "            f\"DenseData(\"\n",
    "            f\"x={tuple(self.x.shape)}, \"\n",
    "            f\"adj={tuple(self.adj.shape)}, \"\n",
    "            f\"mask={tuple(self.mask.shape)})\"\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return DenseData(\n",
    "            self.x[index],\n",
    "            self.adj[index],\n",
    "            self.mask[index]\n",
    "        )\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, DenseData):\n",
    "            raise ValueError(\"Both objects need to be of type DenseData\")\n",
    "        x_concat = torch.cat((self.x, other.x), dim=0)\n",
    "        adj_concat = torch.cat((self.adj, other.adj), dim=0)\n",
    "        mask_concat = torch.cat((self.mask, other.mask), dim=0)\n",
    "        return DenseData(x_concat, adj_concat, mask_concat)\n",
    "\n",
    "\n",
    "class DenseGraphDataset(Dataset):\n",
    "    def __init__(self, pyg_dataset: pygDataset):\n",
    "        self._pyg_dataset = pyg_dataset\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        for el in self._pyg_dataset:\n",
    "            el_dict = el.to_dict()\n",
    "            x = el_dict.pop('x')\n",
    "            adj = to_dense_adj(\n",
    "                el_dict.pop('edge_index'),\n",
    "                edge_attr=el_dict.pop('edge_attr', None)\n",
    "            ).squeeze(0)\n",
    "            mask = th.ones(\n",
    "                x.shape[0],\n",
    "                device=x.device,\n",
    "                dtype=th.bool\n",
    "            )\n",
    "\n",
    "            y = el_dict.pop('y')\n",
    "\n",
    "            remaining_keys = list(sorted(el_dict.keys()))\n",
    "            for k in remaining_keys:\n",
    "                # Concatenate remaning attributes on x\n",
    "                x = th.cat((x, el_dict[k]), dim=1)\n",
    "\n",
    "            self.data.append(\n",
    "                DenseData(\n",
    "                    x,\n",
    "                    adj,\n",
    "                    mask)\n",
    "            )\n",
    "            self.targets.append(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74f6d6f6-7fef-4ffc-b010-59e8eee93a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(DenseData(x=(75, 3), adj=(75, 75), mask=(75,)), tensor([5], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "dense_dataset = DenseGraphDataset(dataset)\n",
    "loader = next(iter(dense_dataset))\n",
    "print(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e32c188-5f14-4928-8636-191490e03006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_collate_fn(batch: List[Tuple[DenseData, th.Tensor]]) -> Tuple[DenseData, th.Tensor]:\n",
    "    max_num_nodes = max([el[0].x.shape[0] for el in batch])\n",
    "    x_list = []\n",
    "    adj_list = []\n",
    "    mask_list = []\n",
    "    y_list = []\n",
    "\n",
    "    for data, y in batch:\n",
    "        n_nodes = data.x.shape[0]\n",
    "        x = pad(data.x, (data.x.ndim-1)*(0, 0) + (0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "        adj = pad(data.adj, (data.adj.ndim-2)*(0, 0) + 2*(0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "        mask = pad(data.mask, (0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "\n",
    "        x_list.append(x)\n",
    "        adj_list.append(adj)\n",
    "        mask_list.append(mask)\n",
    "        y_list.append(y)\n",
    "\n",
    "    x_stacked = th.cat(x_list, dim=0)\n",
    "    adj_stacked = th.cat(adj_list, dim=0)\n",
    "    mask_stacked = th.cat(mask_list, dim=0)\n",
    "    y_stacked = th.cat(y_list, dim=0)\n",
    "\n",
    "    return DenseData(x_stacked, adj_stacked, mask_stacked), y_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92292447-4d6d-42e5-b913-cc4e6a5325ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseData(x=(5, 75, 3), adj=(5, 75, 75), mask=(5, 75)),y=(5,)\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(dense_dataset, batch_size=5, collate_fn=dense_collate_fn)\n",
    "a, y = next(iter(loader))\n",
    "print(f\"{a},y={tuple(y.shape)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05eb5155-1912-402a-8af3-61defee74543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from DataModules import MNISTSuperpixelDataModule\n",
    "\n",
    "# data_module = MNISTSuperpixelDataModule(MNIST_PATH,batch_size=20)\n",
    "# data_module.setup(\"fit\")\n",
    "# a = data_module.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22a3746f-8df0-405d-93ab-186c33830733",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_full = DenseGraphDataset(MNISTSuperpixels(MNIST_PATH, train=True)[:10])\n",
    "to_take = (mnist_full[1] == 0) | (mnist_full[1] == 1)\n",
    "mnist_full = mnist_full[to_take]\n",
    "split = int(len(mnist_full) * 0.9)\n",
    "mnist_train = mnist_full[:split]\n",
    "mnist_val = mnist_full[split:]\n",
    "\n",
    "\n",
    "train = DataLoader(mnist_train, batch_size=5, drop_last=True, shuffle=True, pin_memory=True,\n",
    "                           collate_fn=dense_collate_fn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa1e955-b63a-46e8-a08e-6a0e37522a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Sequence\n",
    "import torch as th\n",
    "from torch_geometric.data import Dataset as pygDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch_geometric.utils import to_dense_adj\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "# TODO: consider store dense repr ons disk.\n",
    "# TODO: it works only with a single feature channel (both on nodes and edges) -> should be true on most of the dataset\n",
    "# TODO: find a wat to access pygDataset attribute without breaking multiprocessing dataloader (__get_attribute__ fails)\n",
    "#  Probably the best practice is to write them explicitly\n",
    "\n",
    "\n",
    "def dense_collate_fn_old(batch: List[Tuple[Sequence[th.Tensor], th.Tensor]]) -> Tuple[Sequence[th.Tensor], th.Tensor]:\n",
    "    num_attr = len(batch[0][0])\n",
    "    max_num_nodes = max([el[0][0].shape[0] for el in batch])\n",
    "    zipped_padded_batch = [[] for _ in range(num_attr+1)] # +1 for y\n",
    "    for x, y in batch:\n",
    "        n_nodes = x[0].shape[0]\n",
    "        for i, attr in enumerate(x):\n",
    "            n_dim = attr.ndim\n",
    "            if i == 0:\n",
    "                # this is the node feature x, padding on first dimension\n",
    "                padded_attr = pad(attr, (n_dim-1)*(0, 0) + (0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "            elif i == 1:\n",
    "                # this is the dense adj, padding on the first two dimension\n",
    "                padded_attr = pad(attr, (n_dim-2)*(0, 0) + 2*(0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "            elif i == 2:\n",
    "                # this is the node_mask, padding on the first (and only) dimension\n",
    "                padded_attr = pad(attr, (0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "            else:\n",
    "                # these are other attributes: we always assume are nodes features or scalars\n",
    "                if attr.ndim == 0 or attr.shape[0] == 1:\n",
    "                    # this is a scalar, no need of padding\n",
    "                    padded_attr = attr\n",
    "                elif attr.ndim < 3:\n",
    "                    # node attributes\n",
    "                    padded_attr = pad(attr, (n_dim-1)*(0, 0) + (0, max_num_nodes - n_nodes)).unsqueeze(0)\n",
    "                else:\n",
    "                    raise ValueError(f'Unsupported attribute with shape {attr.shape}')\n",
    "            zipped_padded_batch[i].append(padded_attr)\n",
    "        zipped_padded_batch[-1].append(y)  # for y\n",
    "\n",
    "    stacked_batch = [th.cat(zipped_padded_batch[i], dim=0) for i in range(num_attr+1)]\n",
    "    return tuple(stacked_batch[:-1]), stacked_batch[-1]\n",
    "\n",
    "\n",
    "class DenseGraphDataset_old(Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "    This class is wrapper of a pygDataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pyg_dataset: pygDataset):\n",
    "        self._pyg_dataset = pyg_dataset\n",
    "\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "        for el in self._pyg_dataset:\n",
    "            el_dict = el.to_dict()\n",
    "            adj = to_dense_adj(el_dict.pop('edge_index'), edge_attr=el_dict.pop('edge_attr', None)).squeeze(0)\n",
    "            x_tuple = [el_dict.pop('x'), adj, th.ones((el.x.shape[0]), device=el.x.device, dtype=th.bool)]\n",
    "            y = el_dict.pop('y')\n",
    "\n",
    "            remaining_keys = list(sorted(el_dict.keys()))\n",
    "            for k in remaining_keys:\n",
    "                x_tuple.append(el_dict[k])\n",
    "\n",
    "            self.data.append(tuple(x_tuple))\n",
    "            self.targets.append(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af3ad0aa-d145-499e-91a4-4180117d4586",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_full = MNISTSuperpixels(MNIST_PATH, train=True).to(device)[:20]\n",
    "data = DenseGraphDataset_old(mnist_full)\n",
    "\n",
    "loader = DataLoader(data, batch_size=5, collate_fn=dense_collate_fn_old)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
